{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1fg76g4IKH2",
        "outputId": "396c49a5-c856-4606-d938-bc87fb0ee018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SGLJZwXJgqB",
        "outputId": "dff2780f-53ac-4cbe-d361-475ad712bf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1] range\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLRgdInoJ08c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxNXX3D5J5-q"
      },
      "outputs": [],
      "source": [
        "def build_cnn(architecture):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First layer is mandatory for the input layer\n",
        "    first_layer = architecture[0]\n",
        "    if first_layer['type'] == 'conv':\n",
        "        model.add(Conv2D(first_layer['filters'], kernel_size=(first_layer['kernel_size'], first_layer['kernel_size']),\n",
        "                         activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "    # Add remaining layers based on the architecture specification\n",
        "    for layer in architecture[1:]:\n",
        "        if layer['type'] == 'conv':\n",
        "            model.add(Conv2D(layer['filters'], kernel_size=(layer['kernel_size'], layer['kernel_size']), activation='relu'))\n",
        "        elif layer['type'] == 'maxpool':\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Add fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))  # Output layer for 10 classes\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZglXQ2YJ-21"
      },
      "outputs": [],
      "source": [
        "def fitness_function(architecture):\n",
        "    try:\n",
        "        model = build_cnn(architecture)\n",
        "        model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=0)\n",
        "        _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return accuracy\n",
        "    except Exception as e:\n",
        "        print(f\"Error during fitness evaluation: {e}\")\n",
        "        return 0  # Return zero if an error occurs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8xka-hMKCaq"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN7_yWjkKGVt"
      },
      "outputs": [],
      "source": [
        "def create_population(pop_size):\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        architecture = []\n",
        "        num_layers = random.randint(2, 4)  # Random number of layers (2 to 4 layers)\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            layer_type = random.choice(['conv', 'maxpool'])\n",
        "            if layer_type == 'conv':\n",
        "                architecture.append({'type': 'conv', 'filters': random.choice([32, 64, 128]),\n",
        "                                     'kernel_size': random.choice([3, 5, 7])})\n",
        "            elif layer_type == 'maxpool':\n",
        "                architecture.append({'type': 'maxpool'})\n",
        "        population.append(architecture)\n",
        "    return population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fY9tCx6KIqt"
      },
      "outputs": [],
      "source": [
        "def tournament_selection(population, fitness_values, tournament_size=3):\n",
        "    selected = random.sample(list(zip(population, fitness_values)), tournament_size)\n",
        "    selected.sort(key=lambda x: x[1], reverse=True)  # Sort by fitness (accuracy)\n",
        "    return selected[0][0]  # Return the best individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc55pDpqKLoq"
      },
      "outputs": [],
      "source": [
        "def crossover(parent1, parent2):\n",
        "    crossover_point = random.randint(0, min(len(parent1), len(parent2)) - 1)\n",
        "    child = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "    return child"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldJngy8iKQdH"
      },
      "outputs": [],
      "source": [
        "def mutate(architecture):\n",
        "    if random.random() < 0.1:  # 10% chance of mutation\n",
        "        mutate_index = random.randint(0, len(architecture) - 1)\n",
        "        if architecture[mutate_index]['type'] == 'conv':\n",
        "            architecture[mutate_index]['filters'] = random.choice([32, 64, 128])\n",
        "            architecture[mutate_index]['kernel_size'] = random.choice([3, 5, 7])\n",
        "        else:\n",
        "            # Add a new conv layer (mutation)\n",
        "            architecture.append({'type': 'conv', 'filters': random.choice([32, 64, 128]), 'kernel_size': random.choice([3, 5, 7])})\n",
        "    return architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQJ_HNF3KUuN"
      },
      "outputs": [],
      "source": [
        "def genetic_algorithm(pop_size=10, generations=5):\n",
        "    # Initialize population\n",
        "    population = create_population(pop_size)\n",
        "\n",
        "    for generation in range(generations):\n",
        "        print(f\"Generation {generation + 1}:\")\n",
        "\n",
        "        # Evaluate fitness for each architecture\n",
        "        fitness_values = [fitness_function(arch) for arch in population]\n",
        "        print(f\"Fitness values: {fitness_values}\")\n",
        "\n",
        "        # Select the best architectures based on fitness\n",
        "        selected_individuals = [tournament_selection(population, fitness_values) for _ in range(pop_size)]\n",
        "\n",
        "        # Create the next generation via crossover and mutation\n",
        "        next_generation = []\n",
        "        while len(next_generation) < pop_size:\n",
        "            parent1, parent2 = random.sample(selected_individuals, 2)\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child)\n",
        "            next_generation.append(child)\n",
        "\n",
        "        population = next_generation\n",
        "\n",
        "    # Return the best architecture found\n",
        "    fitness_values = [fitness_function(arch) for arch in population]\n",
        "    best_architecture = population[fitness_values.index(max(fitness_values))]\n",
        "    return best_architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4S0NGxsKh0K",
        "outputId": "07dc1bf6-3d17-4093-b6bf-eaa4bc6395d8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitness values: [0.32190001010894775, 0.4894999861717224, 0.42640000581741333, 0.5526000261306763, 0.47450000047683716, 0.43970000743865967, 0.5056999921798706, 0.48579999804496765, 0.3215999901294708, 0.5421000123023987]\n",
            "Generation 2:\n",
            "Fitness values: [0.5685999989509583, 0.5598000288009644, 0.49869999289512634, 0.5128999948501587, 0.5016999840736389, 0.5386999845504761, 0.5041999816894531, 0.5358999967575073, 0.46709999442100525, 0.5095000267028809]\n",
            "Generation 3:\n",
            "Fitness values: [0.5206000208854675, 0.4691999852657318, 0.5436000227928162, 0.5590999722480774, 0.474700003862381, 0.5572999715805054, 0.5480999946594238, 0.5817000269889832, 0.5141000151634216, 0.5232999920845032]\n",
            "Generation 4:\n",
            "Fitness values: [0.5412999987602234, 0.5259000062942505, 0.49380001425743103, 0.5644999742507935, 0.5077000260353088, 0.5486000180244446, 0.5626000165939331, 0.4875999987125397, 0.5428000092506409, 0.5340999960899353]\n",
            "Generation 5:\n",
            "Fitness values: [0.5411999821662903, 0.5439000129699707, 0.5464000105857849, 0.5547999739646912, 0.4643999934196472, 0.5347999930381775, 0.5501000285148621, 0.501800000667572, 0.5493999719619751, 0.5789999961853027]\n",
            "Best Architecture Found: [{'type': 'conv', 'filters': 64, 'kernel_size': 5}, {'type': 'maxpool'}, {'type': 'maxpool'}]\n"
          ]
        }
      ],
      "source": [
        "best_architecture = genetic_algorithm(pop_size=10, generations=5)\n",
        "print(f\"Best Architecture Found: {best_architecture}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q1LdzDTLmNp"
      },
      "outputs": [],
      "source": [
        "# Test Case 1: Verify Architecture Creation\n",
        "def test_build_cnn():\n",
        "    architecture = [{'type': 'conv', 'filters': 32, 'kernel_size': 3},\n",
        "                    {'type': 'conv', 'filters': 64, 'kernel_size': 3},\n",
        "                    {'type': 'maxpool'}]\n",
        "\n",
        "    model = build_cnn(architecture)\n",
        "    assert isinstance(model, tf.keras.models.Sequential), \"Model creation failed!\"\n",
        "    print(\"test_build_cnn passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alvur3K0Lr9B"
      },
      "outputs": [],
      "source": [
        "# Test Case 2: Verify Fitness Function\n",
        "def test_fitness_function():\n",
        "    architecture = [{'type': 'conv', 'filters': 32, 'kernel_size': 3},\n",
        "                    {'type': 'maxpool'}]\n",
        "    accuracy = fitness_function(architecture)\n",
        "    assert accuracy >= 0, f\"Invalid fitness value: {accuracy}\"\n",
        "    print(\"test_fitness_function passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ2Vk50iLwlS"
      },
      "outputs": [],
      "source": [
        "# Test Case 3: Verify Population Initialization\n",
        "def test_create_population():\n",
        "    population = create_population(5)\n",
        "    assert len(population) == 5, f\"Population size mismatch: {len(population)}\"\n",
        "    assert all(isinstance(individual, list) for individual in population), \"Population contains non-list architectures\"\n",
        "    print(\"test_create_population passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03cOQwKSLzyy"
      },
      "outputs": [],
      "source": [
        "# Test Case 4: Verify GA Process Runs\n",
        "def test_genetic_algorithm():\n",
        "    best_architecture = genetic_algorithm(pop_size=5, generations=2)\n",
        "    assert isinstance(best_architecture, list), \"Best architecture is not a list\"\n",
        "    print(\"test_genetic_algorithm passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulpmo5DdMLBq"
      },
      "outputs": [],
      "source": [
        "# Test Case 5: Verify Model Evaluation\n",
        "def test_model_evaluation():\n",
        "    architecture = [{'type': 'conv', 'filters': 32, 'kernel_size': 3},\n",
        "                    {'type': 'maxpool'}]\n",
        "\n",
        "    model = build_cnn(architecture)\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=0)  # Train for one epoch\n",
        "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    assert accuracy > 0.1, f\"Model evaluation failed! Accuracy: {accuracy}\"\n",
        "    print(\"test_model_evaluation passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsRrUfzEMOWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7396fa6b-988c-46cb-cac5-a3af229f6390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_build_cnn passed!\n",
            "test_fitness_function passed!\n",
            "test_create_population passed!\n",
            "Generation 1:\n",
            "Fitness values: [0.5715000033378601, 0.45089998841285706, 0.5406000018119812, 0.6162999868392944, 0.4745999872684479]\n",
            "Generation 2:\n",
            "Fitness values: [0.6000000238418579, 0.5956000089645386, 0.5978000164031982, 0.5257999897003174, 0.5360999703407288]\n",
            "test_genetic_algorithm passed!\n",
            "test_model_evaluation passed!\n"
          ]
        }
      ],
      "source": [
        "# Running all test cases\n",
        "test_build_cnn()\n",
        "test_fitness_function()\n",
        "test_create_population()\n",
        "test_genetic_algorithm()\n",
        "test_model_evaluation()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}